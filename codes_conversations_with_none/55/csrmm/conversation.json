{"messages": [{"role": "system", "content": "You are a parallel computing expert. I will provide you a source code in C or C++ and I want you to classify if there is an inefficiency problem in the code. If there is an problem, I want you to classify this problem from the following list: ['Memory/Data locality', 'Micro-architectural inefficiency', 'Vector/SIMD parallelism', 'GPU parallelism', 'Instruction level parallelism', 'Task parallelism', 'small parallel region', 'Inefficeint thread mapping / inefficient block size / Load imbalance', 'Under-parallelization', 'Over-Parallelization', 'Unncessary locks', 'Unncessary strong memory consistency', 'Lock management overhead', 'Unnecessary synchronization', 'Unnecessary process communiction', 'Unnecessary operation/traversal/function call', 'Redundant operation', 'Expensive operation', 'Frequent  function call', 'Inefficient data-structure library', 'Usage of improper data type', 'memory leak', 'repreated memory allocation', 'Redundant memory allocation', 'Slower memory allocation library call', 'Insufficient memory', 'unnecessary data copy', 'sequential I/O operation', 'over parallelization', 'boundary condition check', 'Unintentional Programming logic error', 'Inefficiency due to new compiler version '] and return an answer with the following format and this format only, don't provide explanation: Type: classified_type. If you think there is no inefficiency in the program, return: Type: None"}, {"role": "user", "content": "/*******************************************************\n * Copyright (c) 2016, ArrayFire\n * All rights reserved.\n *\n * This file is distributed under 3-clause BSD license.\n * The complete license agreement can be obtained at:\n * http://arrayfire.com/licenses/BSD-3-Clause\n ********************************************************/\n\n#pragma once\n#pragma once\n#include <kernel_headers/csrmm.hpp>\n#include <program.hpp>\n#include <traits.hpp>\n#include <string>\n#include <mutex>\n#include <map>\n#include <dispatch.hpp>\n#include <Param.hpp>\n#include <debug_opencl.hpp>\n#include <cache.hpp>\n#include <type_util.hpp>\n#include \"scan_dim.hpp\"\n#include \"reduce.hpp\"\n#include \"scan_first.hpp\"\n#include \"config.hpp\"\n\nusing cl::Buffer;\nusing cl::Program;\nusing cl::Kernel;\nusing cl::KernelFunctor;\nusing cl::EnqueueArgs;\nusing cl::NDRange;\nusing std::string;\n\nnamespace opencl\n{\n    namespace kernel\n    {\n        static const int MAX_CSRMM_GROUPS = 4096;\n        template<typename T>\n        void csrmm_nt(Param out,\n                      const Param &values, const Param &rowIdx, const Param &colIdx,\n                      const Param &rhs, const T alpha, const T beta)\n        {\n            try {\n                bool use_alpha = (alpha != scalar<T>(1.0));\n                bool use_beta = (beta != scalar<T>(0.0));\n                bool use_greedy = (getActiveDeviceType() == AFCL_DEVICE_TYPE_GPU) &&\n                    ((getActivePlatform() == AFCL_PLATFORM_AMD) ||\n                     (getActivePlatform() == AFCL_PLATFORM_NVIDIA));\n\n                std::string ref_name =\n                    std::string(\"csrmm_\") +\n                    std::string(dtype_traits<T>::getName()) +\n                    std::string(\"_\") +\n                    std::to_string(use_alpha) +\n                    std::string(\"_\") +\n                    std::to_string(use_beta) +\n                    std::string(\"_\") +\n                    std::to_string(use_greedy);\n\n                int device = getActiveDeviceId();\n                auto idx = kernelCaches[device].find(ref_name);\n                kc_entry_t entry;\n\n                if (idx == kernelCaches[device].end()) {\n\n                    std::ostringstream options;\n                    options << \" -D T=\" << dtype_traits<T>::getName();\n                    options << \" -D USE_ALPHA=\" << use_alpha;\n                    options << \" -D USE_BETA=\" << use_beta;\n                    options << \" -D USE_GREEDY=\" << use_greedy;\n                    options << \" -D THREADS_PER_GROUP=\" << THREADS_PER_GROUP;\n\n                    if (std::is_same<T, double>::value ||\n                        std::is_same<T, cdouble>::value) {\n                        options << \" -D USE_DOUBLE\";\n                    }\n                    if (std::is_same<T, cfloat>::value ||\n                        std::is_same<T, cdouble>::value) {\n                        options << \" -D IS_CPLX=1\";\n                    } else {\n                        options << \" -D IS_CPLX=0\";\n                    }\n\n                    const char *ker_strs[] = {csrmm_cl};\n                    const int   ker_lens[] = {csrmm_cl_len};\n\n                    Program prog;\n                    buildProgram(prog, 1, ker_strs, ker_lens, options.str());\n                    entry.prog = new Program(prog);\n                    entry.ker  = new Kernel[2];\n                    entry.ker[0] = Kernel(*entry.prog, \"csrmm_nt\");\n                    // FIXME: Change this after adding another kernel\n                    entry.ker[1] = Kernel(*entry.prog, \"csrmm_nt\");\n                } else {\n                    entry = idx->second;\n                }\n\n                auto csrmm_nt_kernel = entry.ker[0];\n                auto csrmm_nt_func = KernelFunctor<Buffer,\n                                                   Buffer, Buffer, Buffer,\n                                                   int, int, int,\n                                                   Buffer, KParam, T, T, Buffer>(csrmm_nt_kernel);\n                NDRange local(THREADS_PER_GROUP, 1);\n                int M = rowIdx.info.dims[0] - 1;\n                int N = rhs.info.dims[1];\n                int K = rhs.info.dims[0];\n\n                int groups_x = divup(K, local[0]);\n                int groups_y = divup(M, REPEAT);\n                groups_y = std::min(groups_y, MAX_CSRMM_GROUPS);\n                NDRange global(local[0] * groups_x, local[1] * groups_y);\n\n                std::vector<int> count(groups_x);\n                cl::Buffer *counter = bufferAlloc(count.size() * sizeof(int));\n                getQueue().enqueueWriteBuffer(*counter, CL_TRUE,\n                                              0,\n                                              count.size() * sizeof(int),\n                                              (void *)count.data());\n\n                csrmm_nt_func(EnqueueArgs(getQueue(), global, local),\n                              *out.data, *values.data, *rowIdx.data, *colIdx.data,\n                              M, N, K, *rhs.data, rhs.info, alpha, beta, *counter);\n\n                bufferFree(counter);\n            } catch (cl::Error &ex) {\n                CL_TO_AF_ERROR(ex);\n            }\n        }\n    }\n}\n"}, {"role": "assistant", "content": "Type: None"}]}